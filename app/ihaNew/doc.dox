/**
 * @ingroup icub_applications
 *
 * \defgroup icub_iha2 ihaNew

 *
 * \brief  Interaction History Architecture Version 2.0 (IHA2) Application
 
In this architecture a metric space of experiences accumulated over ontogeny related using informational measures is used to direct future experiences. This application is a branch from the original version of IHA (also in the repository). This new version adds several new modules to support the use of human gaze and an electronic drum as input and to further support the learning of turn-taking behavior sequences using a short-term memory. The demo associated with this application demonstrates an expanded range of social interaction behaviors motivated by this richer input, including simple turn-taking in the form of drumming and peek-a-boo. Additionally, the organization of the modules and how they connect to one another has been changed for the sake of clarity and simplicity.

This application consists of a number of scripts and configuration files that are used to start and stop a number of interconnecting processes.  See \ref icub_iha2_module. Because of the way IHA logs data, the modules may not all be started using the xml application manager. Supporting modules may be started through the application manager, but the core IHA modules must be started via scripts. This process will be explained in detail below.

\section iha2_intro Introduction

An interaction history is a collection of past "experiences" of a robot that can be used to generate future action based on its new experiences. At the heart of the architecture is a "metric space of experiences" where an experience can be compared with any other in terms of their informational-theoretic relationships. This comparison is a metric and so experiences can be "placed" in a space with distances relative to each other.

The Interaction History Architecture selects those experiences from the history that are "closest" to the current experience. Then it chooses one of those experiences and the action that was executed in the past just after that experience, and executes that action. The choice is determined by proximity in the metric space as well as the subjective value of the experience in relation to the reward received in the past.

This new version of IHA is intended to be used by a human wearing a gaze tracking device. Data from this device provides one of the sources of reward feedback to the robot. There are command-line flags for all the core modules that will run the application without gaze input if such a device is not available.

\image html IHAArchitectureV5.jpg

The architecture also includes mechanisms for "forgetting" and formation of proto-typical experiences. The first simply deletes those experiences with low subjective value, and the second merges together experiences based on their proximity in the space. 

In order to make use of sequential information about recently experienced data (which is relevant to behaviors that involve turn-taking), a short term memory module has been added to the application. This short term memory is used to compute an additional source of reward feedback for the robot.

You can find out more about the architecture and existing experiments in the following 
\link http://www.robotcub.net/index.php/robotcub/more_information/deliverables/ RobotCub Deliverables
\endlink and papers:

 - Paper on social interaction demo using V2 architecture
 \link http://www.robotcub.org/misc/review5/papers/09_Broz_etal.pdf 09_Broz_etal.pdf
 \endlink (ref: Broz, F., Kose-Bagci, H., Nehaniv, C.L., Dautenhahn, K., Learning behavior for a social interaction game with a childlike humanoid robot, Social Learning in Interactive Scenarios Workshop, Humanoids 2009, Paris, France, 7 December, 2009.)
 - D6.4 : A description of IHA V1 along with experimental details of the peekaboo experiment on KasparII
 \link http://www.robotcub.net/index.php/robotcub/content/download/1144/4009/file/d6.4.pdf D6.4pdf
 \endlink
 - D6.2 : Sec 3 and App C/D discuss scalability issues and T-Maze experiment (
 \link http://www.robotcub.net/index.php/robotcub/content/download/1060/3735/file/RC_UNIHER_KD_Deliverable_D6.2.pdf D6.2.pdf (Appendices D and E)
 \endlink )
 - Adaptive Behaviour Journal article - description of IHA and research on Aibo (Ball path prediction and Peekaboo). Available as
 \link http://www.robotcub.net/index.php/robotcub/content/download/1060/3735/file/RC_UNIHER_KD_Deliverable_D6.2.pdf D6.2.pdf (Appendix C)
 \endlink (ref: N.A. Mirza, C.L. Nehaniv, K. Dautenhahn, R. teBoekhorst (2007) Grounded Sensorimotor Interaction Histories in an Information Theoretic Metric Space for Robot Ontogeny, \e Adaptive \e Behaviour, SAGE Publications. \b 15 (2) pp 167-187 )
 - Also N.A. Mirza PhD Thesis

\section ihaNew_process_flow Process Flow

The New Interaction History Architecture consists of a number of interoperating processes implemented as modules (deriving from yarp::os::Module class). Their relationship is described (for the iCub) in the following diagram.

\image html IHANewFlow_iCub.jpg

\section dep_sec Dependencies
-# When connecting to a physical robot:
  - This module assumes \ref icub_iCubInterface2 is already running.
  - Assumes that the cameras on the robot have been started
  - By default, assumes that a gaze tracking system is serving data. This option may be turned off using command-line flags. The system has been tested with an ASL MobileEye gaze tracker, but the drivers for the tracker contain proprietary code and are not a part of the iCub software release. Any gaze tracker which is capable of providing a scene image and gaze coordinates in a scene image pixel format may be used instead.
  - This version of IHA is not intended for use in the simulator because way that gaze tracking is used cannot be replicated in simulation.

\section modules_sec Instantiated Modules
List here the modules that are instantiated by this application:
- \ref icub_iha_ExperienceMetricSpace 
- \ref icub_iha_ActionSelection 
- \ref icub_iha2_AudioAnalyser
- \ref icub_iha2_IcubControl 
- \ref icub_iha2_IhaFaceDetect 
- \ref icub_iha2_Dynamics 
- \ref icub_iha2_MobileEye 
- \ref icub_iha2_SensorMotorInterface 
- \ref icub_iha2_Memory 
- \ref icub_iha_SoundSensor 
- \ref icub_iha_StatusMonitor 

\section parameters_sec Parameters
Application parameters are contained in the files config_ports.sh and config_machines.sh for the modules controlled by the scripts. Other parameters are listed in the xml files.

\b config_ports.sh 
- contains name of the various robot ports (including cameras) and the names of the module in/out ports

\b config_machines.sh
- contains a list of all the machines available for running processes along with a mapping of processors to machines.  The machine LOCAL is special: if processes are started on local they do not use the \c yarp \c run service.

\section config_sec Configuration Files

- Action definitions, referenced by multiple modules 
 - conf/iha_actiondefs.ini         
- \ref icub_iha2_IcubControl iCub Control 
 - conf/ihaIcubControl.ini
- \ref icub_iha_ActionSelection Action Selection 
 - conf/ihaActionSelection.ini
- \ref icub_iha2_AudioAnalyser Audio Analyser 
 - conf/ihaAudioAnalyser.ini
- \ref icub_iha_ExperienceMetricSpace Experience Metric Space 
 - conf/ihaExperienceMetricSpace.ini
- \ref icub_iha2_IhaFaceDetect Face Detection 
 - conf/ihaIhaFaceDetect.ini
- \ref icub_iha2_IhaFaceDetect Self Face Detection 
 - conf/ihaIhaSelfFaceDetect.ini
- \ref icub_iha2_Dynamics Motivation Dynamics 
 - conf/ihaMotivationDynamics.ini
- \ref icub_iha2_SensorMotorInterface Sensor Motor Interface 
 - conf/ihaSensorMotorInterface.ini
- \ref icub_iha2_Memory Short Term Memory 
 - conf/ihaShortTermMemory.ini
- \ref icub_iha_SoundSensor Sound Sensor 
 - conf/ihaSoundSensor.ini
- \ref icub_iha_StatusMonitor Status Monitor 
 - conf/ihaStatusMonitor.ini
- \ref icub_iha_SensorsFileWriter Sensors File Writer
 - conf/ihaSensorsFileWriter.ini

 
\section example_sec How to run the application
 
<b> GENERAL NOTES ON USAGE </b>

-#  To start and stop the system you first need to run and connect the supporting modules which are configured in the supporting*.xml file. Versions exist that will configure the modules to run either with or without the gaze tracker.

-# The core modules may then be started and stopped using the "numbered scripts" as follows. Where necessary separate versions exist to run the application with or without gaze tracker input.
  - 10_run_supporting.sh (deprecated)
  - 20_connect_supporting.sh (deprecated)
  - 30_run_and_connect_iha_processes.sh
  - 30_run_and_connect_iha_processes_wo_gaze.sh
  - 40_run_controller.sh
  - 70_stop_controller.sh
  - 80_stop_iha_processes.sh
  - 80_stop_iha_processes_wo_gaze.sh
  - 90_stop_supporting.sh (deprecated)
-#  To run different processes on different machines, change the processor map in 
      config_machines.sh and in the xml files
-#  The recommended way to stop individual processes (that are not already under control of the application manager) is to use the modular scripts
      e.g. facedetector.sh stop
	  In extreme cases there is also usually a kill option. 
-#  There are two config scripts containing variables. The first is the machine 
      mapping script config_machines.sh, the other, config_ports.sh, holds all the port 
	  names so things can be connected easily in different scripts.

<b> SCRIPT STRUCTURE </b>

<i> start_stop_utils.sh </i>

  This script provides functions to start and stop individual modules or processes 
  on the local or remote machines. 

  You can choose to start locally or remotely, with logging or without and also you can 
  choose to start the process in its own spawned xterm

<i> Init scripts </i>

  These scripts are named for the processes the look after, e.g. viewers.sh
  They always take a parameter e.g. [start|stop|kill|connect]


<i> High-level scripts </i>

  These just simplify the process of starting and stopping the system as you 
  can just start the scripts in order of number (and stop in order) without having to know
  or remember what should be started first.  They consist of lists of init scripts.


\author Frank Broz and Naeem Assif Mirza

Copyright (C) 2009 RobotCub Consortium

CopyPolicy: Released under the terms of the GNU GPL v2.0.

This file can be edited at \in app/ihaNew/doc.dox
 *
 */

